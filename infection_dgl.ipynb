{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Using backend: pytorch\n"]},{"ename":"ImportError","evalue":"attempted relative import with no known parent package","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-122a998d0f29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#from explain_methods import *\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#from models import Net1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodels_dgl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNet1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"]}],"source":["import random\n","from collections import defaultdict\n","\n","import mlflow\n","import networkx as nx\n","import numpy as np\n","import torch\n","#from torch_geometric.utils import from_networkx\n","import dgl\n","\n","from tqdm import tqdm as tq\n","\n","import json\n","import os\n","import tempfile\n","import time\n","from collections import defaultdict\n","import random\n","# Benchmark \n","import mlflow\n","import torch.nn.functional as F\n","from tqdm import tqdm as tq\n","\n","#from explain_methods import *\n","#from models import Net1\n","#from .models_dgl import Net1"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","from torch.nn import Sequential, Linear, ReLU\n","#from torch_geometric.nn import GNNExplainer, GINConv, MessagePassing, GCNConv, GraphConv\n","from dgl.nn import GraphConv#GCNConv\n","\n","class Net1(torch.nn.Module):\n","    def __init__(self, num_node_features, num_classes, num_layers, concat_features, conv_type):\n","        super(Net1, self).__init__()\n","        dim = 32\n","        self.convs = torch.nn.ModuleList()\n","        if conv_type == 'GraphConv':#'GCNConv':\n","            conv_class = GraphConv\n","            #kwargs = {'add_self_loops': False}\n","        #elif conv_type == 'GraphConv':\n","        #    conv_class = GraphConv\n","        #    kwargs = {}\n","        else:\n","            raise RuntimeError(f\"conv_type {conv_type} not supported\")\n","\n","        self.convs.append(conv_class(num_node_features, dim, allow_zero_in_degree = True))#, **kwargs))\n","        for i in range(num_layers - 1):\n","            self.convs.append(conv_class(dim, dim, allow_zero_in_degree = True))#, **kwargs))\n","        self.concat_features = concat_features\n","        if concat_features:\n","            self.fc = Linear(dim * num_layers + num_node_features, num_classes)\n","        else:\n","            self.fc = Linear(dim, num_classes)\n","\n","    def forward(self, g, x, weight = None, edge_weight=None):\n","        xs = [x]\n","        for conv in self.convs:\n","            x = conv(g, x, weight, edge_weight)\n","            x = F.relu(x)\n","            xs.append(x)\n","        if self.concat_features:\n","            x = torch.cat(xs, dim=1)\n","        x = self.fc(x)\n","        return F.log_softmax(x, dim=1)\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["\n","class Benchmark(object):\n","    '''\n","    三个Benchmark的父类\n","    \n","    需要子类继承：create_dataset和evaluate_explanation这两个方法\n","    '''\n","    NUM_GRAPHS = 2\n","    TEST_RATIO = 0.5\n","    PGMEXPLAINER_SUBSAMPLE_PER_GRAPH = 20\n","    METHODS = ['pagerank', 'pgmexplainer', 'occlusion', 'distance', 'gradXact', 'random', 'sa_node',\n","               'ig_node', 'sa', 'ig', 'gnnexplainer',\n","               'subgraphx']\n","    LR = 0.0003\n","    EPOCHS = 400\n","    WEIGHT_DECAY = 0\n","\n","    def __init__(self, sample_count, num_layers, concat_features, conv_type):\n","        arguments = {\n","            'sample_count': sample_count,\n","            'num_layers': num_layers,\n","            'concat_features': concat_features,\n","            'conv_type': conv_type,\n","            'num_graphs': self.NUM_GRAPHS,\n","            'test_ratio': self.TEST_RATIO,\n","        }\n","        self.sample_count = sample_count\n","        self.num_layers = num_layers\n","        self.concat_features = concat_features\n","        self.conv_type = conv_type\n","        mlflow.log_params(arguments)\n","        mlflow.log_param('PGMEXPLAINER_SUBSAMPLE_PER_GRAPH', self.PGMEXPLAINER_SUBSAMPLE_PER_GRAPH)\n","        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    def create_dataset(self):\n","        raise NotImplementedError\n","\n","    def evaluate_explanation(self, explain_function, model, test_dataset, explain_name):\n","        raise NotImplementedError\n","\n","    def subsample_nodes(self, explain_function, nodes):\n","        if explain_function.explain_function != explain_pgmexplainer:\n","            return nodes\n","        return random.sample(nodes, self.PGMEXPLAINER_SUBSAMPLE_PER_GRAPH)\n","\n","    @staticmethod\n","    def aggregate_directions(edge_mask, edge_index):\n","        edge_values = defaultdict(float)\n","        for x in range(len(edge_mask)):\n","            u, v = edge_index[:, x]\n","            u, v = u.item(), v.item()\n","            if u > v:\n","                u, v = v, u\n","            edge_values[(u, v)] += edge_mask[x]\n","        return edge_values\n","\n","    def train(self, model, optimizer, train_loader):\n","        model.train()\n","        loss_all = 0\n","        for data in train_loader:\n","            data = data.to(self.device)\n","            optimizer.zero_grad()\n","            output = model(data, data.ndata['x'])\n","            loss = F.nll_loss(output, data.ndata['y'])\n","            loss.backward()\n","            loss_all += loss.item()\n","            optimizer.step()\n","        return loss_all / len(train_loader)\n","\n","    def test(self, model, loader):\n","        model.eval()\n","\n","        correct = 0\n","        total = 0\n","        for data in loader:\n","            data = data.to(self.device)\n","            output = model(data, data.ndata['x'])\n","            pred = output.max(dim=1)[1]\n","            correct += pred.eq(data.ndata['y']).sum().item()\n","            total += len(data.ndata['y'])\n","        return correct / total\n","\n","    def train_and_test(self, model, train_loader, test_loader):\n","        optimizer = torch.optim.Adam(model.parameters(), lr=self.LR, weight_decay=self.WEIGHT_DECAY)\n","        mlflow.log_param('weight_decay', self.WEIGHT_DECAY)\n","        mlflow.log_param('lr', self.LR)\n","        mlflow.log_param('epochs', self.EPOCHS)\n","        pbar = tq(range(self.EPOCHS))\n","        for epoch in pbar:\n","            train_loss = self.train(model, optimizer, train_loader)\n","            train_acc = self.test(model, train_loader)\n","            test_acc = self.test(model, test_loader)\n","            pbar.set_postfix(train_loss=train_loss, train_acc=train_acc, test_acc=test_acc)\n","        return train_acc, test_acc\n","\n","    def is_trained_model_valid(self, test_acc):\n","        return True\n","\n","    def run(self):\n","        print(f\"Using device {self.device}\")\n","        benchmark_name = self.__class__.__name__\n","        all_explanations = defaultdict(list)\n","        all_runtimes = defaultdict(list)\n","        for experiment_i in tq(range(self.sample_count)):\n","            dataset = [self.create_dataset() for i in range(self.NUM_GRAPHS)]\n","            split_point = int(len(dataset) * self.TEST_RATIO)\n","            test_dataset = dataset[:split_point]\n","            train_dataset = dataset[split_point:]\n","            data = dataset[0]\n","            model = Net1(data.num_node_features, data.num_classes, self.num_layers, self.concat_features,\n","                         self.conv_type).to(\n","                self.device)\n","            train_acc, test_acc = self.train_and_test(model, train_dataset, test_dataset)\n","            if not self.is_trained_model_valid(test_acc):\n","                print('Model accuracy was not valid, ignoring this experiment')\n","                continue\n","            model.eval()\n","            metrics = {\n","                'train_acc': train_acc,\n","                'test_acc': test_acc,\n","            }\n","            mlflow.log_metrics(metrics, step=experiment_i)\n","\n","            for explain_name in self.METHODS:\n","                explain_function = eval('explain_' + explain_name)\n","                duration_samples = []\n","\n","                def time_wrapper(*args, **kwargs):\n","                    start_time = time.time()\n","                    result = explain_function(*args, **kwargs)\n","                    end_time = time.time()\n","                    duration_seconds = end_time - start_time\n","                    duration_samples.append(duration_seconds)\n","                    return result\n","\n","                time_wrapper.explain_function = explain_function\n","                accs = self.evaluate_explanation(time_wrapper, model, test_dataset, explain_name)\n","                print(f'Benchmark:{benchmark_name} Run #{experiment_i + 1}, Explain Method: {explain_name}, Accuracy: {np.mean(accs)}')\n","                all_explanations[explain_name].append(list(accs))\n","                all_runtimes[explain_name].extend(duration_samples)\n","                metrics = {\n","                    f'explain_{explain_name}_acc': np.mean(accs),\n","                    f'time_{explain_name}_s_avg': np.mean(duration_samples),\n","                }\n","                with tempfile.TemporaryDirectory() as tmpdir:\n","                    file_path = os.path.join(tmpdir, 'accuracies.json')\n","                    json.dump(all_explanations, open(file_path, 'w'), indent=2)\n","                    mlflow.log_artifact(file_path)\n","                mlflow.log_metrics(metrics, step=experiment_i)\n","            print(f'Benchmark:{benchmark_name} Run #{experiment_i + 1} finished. Average Explanation Accuracies for each method:')\n","            accuracies_summary = {}\n","            for name, run_accs in all_explanations.items():\n","                run_accs = [np.mean(single_run_acc) for single_run_acc in run_accs]\n","                accuracies_summary[name] = {'avg': np.mean(run_accs), 'std': np.std(run_accs), 'count': len(run_accs)}\n","                print(f'{name} : avg:{np.mean(run_accs)} std:{np.std(run_accs)}')\n","            runtime_summary = {}\n","            for name, runtimes in all_runtimes.items():\n","                runtime_summary[name] = {'avg': np.mean(runtimes), 'std': np.std(runtimes)}\n","            with tempfile.TemporaryDirectory() as tmpdir:\n","                file_path = os.path.join(tmpdir, 'summary.json')\n","                summary = {'accuracies': accuracies_summary, 'runtime': runtime_summary}\n","                json.dump(summary, open(file_path, 'w'), indent=2)\n","                mlflow.log_artifact(file_path)\n","#Infection\n","class Infection(Benchmark):\n","    NUM_GRAPHS = 10\n","    TEST_RATIO = 0.4\n","    LR = 0.005\n","\n","    @staticmethod\n","    def get_accuracy(correct_ids, edge_mask, edge_index):\n","        correct_count = 0\n","        correct_edges = list(zip(correct_ids, correct_ids[1:]))\n","\n","        for x in np.argsort(-edge_mask)[:len(correct_ids)]:\n","            u, v = edge_index[:, x]\n","            u, v = u.item(), v.item()\n","            if (u, v) in correct_edges:\n","                correct_count += 1\n","        return correct_count / len(correct_edges)\n","\n","    @staticmethod\n","    def get_accuracy_undirected(correct_ids, edge_values):\n","        correct_count = 0\n","        correct_edges = list(zip(correct_ids, correct_ids[1:]))\n","\n","        top_edges = list(sorted([(-value, edge) for edge, value in edge_values.items()]))[:len(correct_ids)]\n","        for _, (u, v) in top_edges:\n","            if (u, v) in correct_edges or (v, u) in correct_edges:\n","                correct_count += 1\n","        return correct_count / len(correct_edges)\n","\n","    def create_dataset(self):\n","        max_dist = self.num_layers  # anything larger than max_dist has a far away label\n","        g = nx.erdos_renyi_graph(250, 0.004, directed=True)#1000\n","        N = len(g.nodes())\n","        infected_nodes = random.sample(g.nodes(), 50)\n","        g.add_node('X')  # dummy node for easier computation, will be removed in the end\n","        for u in infected_nodes:\n","            g.add_edge('X', u)\n","        shortest_path_length = nx.single_source_shortest_path_length(g, 'X')\n","        unique_solution_nodes = []\n","        unique_solution_explanations = []\n","        labels = []\n","        features = np.zeros((N, 2))\n","        for i in range(N):\n","            if i == 'X':\n","                continue\n","            length = shortest_path_length.get(i, 100) - 1  # 100 is inf distance\n","            labels.append(min(max_dist + 1, length))\n","            col = 0 if i in infected_nodes else 1\n","            features[i, col] = 1\n","            if 0 < length <= max_dist:\n","                path_iterator = iter(nx.all_shortest_paths(g, 'X', i))\n","                unique_shortest_path = next(path_iterator)\n","                if next(path_iterator, 0) != 0:\n","                    continue\n","                unique_shortest_path.pop(0)  # pop 'X' node\n","                if len(unique_shortest_path) == 0:\n","                    continue\n","                unique_solution_explanations.append(unique_shortest_path)\n","                unique_solution_nodes.append(i)\n","        g.remove_node('X')\n","        data = dgl.from_networkx(g)\n","        data.ndata['x'] = torch.tensor(features, dtype=torch.float)\n","        #data.x = torch.tensor(features, dtype=torch.float)\n","        data.ndata['y'] = torch.tensor(labels)\n","        #data.y = torch.tensor(labels)\n","        data.unique_solution_nodes = unique_solution_nodes\n","        data.unique_solution_explanations = unique_solution_explanations\n","        data.num_classes = 1 + max_dist + 1\n","        data.num_node_features = 2\n","        print('created one')\n","        return data\n","\n","    def is_trained_model_valid(self, test_acc):\n","        return test_acc > 0.999\n","\n","    def evaluate_explanation(self, explain_function, model, test_dataset, explain_name):\n","        accs = []\n","        misclassify_count = 0\n","        for data in test_dataset:\n","            _, pred = model(data, data.ndata['x']).max(dim=1)#data.x data.edge_index\n","            nodes_to_test = list(zip(data.unique_solution_nodes, data.unique_solution_explanations))\n","            nodes_to_test = self.subsample_nodes(explain_function, nodes_to_test)\n","            pbar = tq(nodes_to_test, disable=False)\n","            tested_nodes = 0\n","            for node_idx, correct_ids in pbar:\n","                if pred[node_idx] != data.y[node_idx]:\n","                    misclassify_count += 1\n","                    continue\n","                tested_nodes += 1\n","                edge_mask = explain_function(model, node_idx, data.ndata['x'], data.edges(), data.ndata['y'][node_idx].item())\n","                explain_acc = self.get_accuracy(correct_ids, edge_mask, data.edges())\n","                accs.append(explain_acc)\n","                pbar.set_postfix(acc=np.mean(accs))\n","            mlflow.log_metric('tested_nodes_per_graph', tested_nodes)\n","        return accs"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/10 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Using device cuda\n","created one\n","created one\n","created one\n","created one\n","created one\n","created one\n","created one\n","created one\n","created one\n","created one\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 400/400 [00:36<00:00, 10.97it/s, test_acc=0.999, train_acc=1, train_loss=0.00372]\n"," 10%|█         | 1/10 [00:36<05:30, 36.67s/it]"]},{"name":"stdout","output_type":"stream","text":["Model accuracy was not valid, ignoring this experiment\n","created one\n","created one\n","created one\n","created one\n","created one\n","created one\n","created one\n","created one\n","created one\n"]},{"name":"stderr","output_type":"stream","text":[]},{"name":"stdout","output_type":"stream","text":["created one\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 400/400 [00:36<00:00, 10.93it/s, test_acc=0.999, train_acc=1, train_loss=0.00362]\n"," 20%|██        | 2/10 [01:13<04:54, 36.76s/it]"]},{"name":"stdout","output_type":"stream","text":["Model accuracy was not valid, ignoring this experiment\n","created one\n","created one\n","created one\n","created one\n","created one\n","created one\n","created one\n","created one\n","created one\n","created one\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 400/400 [00:36<00:00, 10.96it/s, test_acc=1, train_acc=1, train_loss=0.00368]\n"," 20%|██        | 2/10 [01:50<07:20, 55.09s/it]\n"]},{"ename":"NameError","evalue":"name 'explain_pagerank' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-735ea355e4c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInfection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'GraphConv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-3-a4b2e5240f2d>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mexplain_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMETHODS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                 \u001b[0mexplain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'explain_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mexplain_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m                 \u001b[0mduration_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'explain_pagerank' is not defined"]}],"source":["A = Infection(10,4,True,'GraphConv')\n","A.run()"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Using backend: pytorch\n"]}],"source":["import dgl"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["OutMultiEdgeDataView([(0, 1), (1, 2)])"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["g = dgl.graph(([0,1],[1,2]))\n","g.xxx = '123'\n","netg = g.to_networkx()\n","netg.edges()"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["(tensor([0, 1]), tensor([1, 2]))"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["g.edges()"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":["{(0, 1): 0}"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["a,b  = list(enumerate(zip(*[g.edges()[0].cpu().numpy(),g.edges()[1].cpu().numpy()])))[0]\n","c = dict()\n","c[b] = a\n","c"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"ename":"TypeError","evalue":"combinations(): argument 'r' (position 2) must be int, not Tensor","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-7aeefcfd7c13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombinations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: combinations(): argument 'r' (position 2) must be int, not Tensor"]}],"source":["import torch \n","torch.combinations(g.edges()[0],g.edges()[1])\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"interpreter":{"hash":"b91fd5d531450f9f66c1b286a62fef5f077805e284adac94e49538db1b8406df"},"kernelspec":{"display_name":"Python 3.8.0 64-bit ('expgnndgl': conda)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
